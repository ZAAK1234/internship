{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0722a1b7",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank \n",
    "B) Name \n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f1b0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium. webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException,ElementClickInterceptedException\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175a4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487aa2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b67aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "uploder=[]\n",
    "View=[]\n",
    "Date=[]\n",
    "dr=webdriver.Chrome()\n",
    "dr.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "nm=dr.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "for i in nm:\n",
    "    \n",
    "    nm_=i.text\n",
    "    rnm=re.findall(r'([^\"]+)',nm_)[0]\n",
    "                   \n",
    "    name.append(rnm)\n",
    "    time.sleep(5)\n",
    "    upldr=dr.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "for i in upldr:\n",
    "    upld=i.text\n",
    "    uploder.append(upld)\n",
    "    time.sleep(5)\n",
    "    view=dr.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "\n",
    "for i in view:\n",
    "    vw=i.text\n",
    "    View.append(vw)\n",
    "    time.sleep(5)\n",
    "    dt=dr.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "for i in dt:\n",
    "    dt_=i.text\n",
    "    Date.append(dt_)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e5143e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>View</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>14.09</td>\n",
       "      <td>14.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.87</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.62</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.15</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Learning Colors ‚Äì Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.07</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Masha and the Bear ‚Äì Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Shree Hanuman Chalisa</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name  \\\n",
       "0                            Baby Shark Dance   \n",
       "1                                   Despacito   \n",
       "2                        Johny Johny Yes Papa   \n",
       "3                                   Bath Song   \n",
       "4                                Shape of You   \n",
       "5                               See You Again   \n",
       "6                           Wheels on the Bus   \n",
       "7                 Phonics Song with Two Words   \n",
       "8                                 Uptown Funk   \n",
       "9   Learning Colors ‚Äì Colorful Eggs on a Farm   \n",
       "10                              Gangnam Style   \n",
       "11   Masha and the Bear ‚Äì Recipe for Disaster   \n",
       "12                             Dame Tu Cosita   \n",
       "13                                     Axel F   \n",
       "14                                      Sugar   \n",
       "15                             Counting Stars   \n",
       "16                        Baa Baa Black Sheep   \n",
       "17                                       Roar   \n",
       "18                             Lakdi Ki Kathi   \n",
       "19           Waka Waka (This Time for Africa)   \n",
       "20                                      Sorry   \n",
       "21                          Thinking Out Loud   \n",
       "22          Humpty the train on a fruits ride   \n",
       "23                      Shree Hanuman Chalisa   \n",
       "24                                 Dark Horse   \n",
       "25                                    Perfect   \n",
       "26                                 Let Her Go   \n",
       "27                                      Faded   \n",
       "28                             Girls Like You   \n",
       "29                                    Lean On   \n",
       "\n",
       "                                             Uploader   View Upload Date  \n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories  14.09       14.09  \n",
       "1                                          Luis Fonsi   8.38        8.38  \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.87        6.87  \n",
       "3                          Cocomelon - Nursery Rhymes   6.62        6.62  \n",
       "4                                          Ed Sheeran   6.20        6.20  \n",
       "5                                         Wiz Khalifa   6.17        6.17  \n",
       "6                          Cocomelon - Nursery Rhymes   5.88        5.88  \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs   5.70        5.70  \n",
       "8                                         Mark Ronson   5.15        5.15  \n",
       "9                                         Miroshka TV   5.07        5.07  \n",
       "10                                                Psy   5.05        5.05  \n",
       "11                                         Get Movies   4.58        4.58  \n",
       "12                                      Ultra Records   4.55        4.55  \n",
       "13                                         Crazy Frog   4.34        4.34  \n",
       "14                                           Maroon 5   4.00        4.00  \n",
       "15                                        OneRepublic   3.97        3.97  \n",
       "16                         Cocomelon - Nursery Rhymes   3.96        3.96  \n",
       "17                                         Katy Perry   3.96        3.96  \n",
       "18                                       Jingle Toons   3.91        3.91  \n",
       "19                                            Shakira   3.85        3.85  \n",
       "20                                      Justin Bieber   3.77        3.77  \n",
       "21                                         Ed Sheeran   3.73        3.73  \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.73        3.73  \n",
       "23                              T-Series Bhakti Sagar   3.69        3.69  \n",
       "24                                         Katy Perry   3.67        3.67  \n",
       "25                                         Ed Sheeran   3.67        3.67  \n",
       "26                                          Passenger   3.61        3.61  \n",
       "27                                        Alan Walker   3.59        3.59  \n",
       "28                                           Maroon 5   3.56        3.56  \n",
       "29                               Major Lazer Official   3.55        3.55  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_rnk=pd.DataFrame({})\n",
    "yt_rnk['Name']=name\n",
    "yt_rnk['Uploader']=uploder\n",
    "yt_rnk['View']=View\n",
    "yt_rnk['Upload Date']=Date\n",
    "yt_rnk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1055c",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "2. Scrape the details team India‚Äôs international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/. \n",
    "You need to find following details: \n",
    "A) Series \n",
    "B) Place \n",
    "C) Date \n",
    "D) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f545cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Series  \\\n",
       "0  ENGLAND TOUR OF INDIA 2023-24   \n",
       "1    INDIA TOUR OF ZIMBABWE 2024   \n",
       "2    INDIA TOUR OF ZIMBABWE 2024   \n",
       "3    INDIA TOUR OF ZIMBABWE 2024   \n",
       "4    INDIA TOUR OF ZIMBABWE 2024   \n",
       "5    INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                               Place           Date  \\\n",
       "0  Himachal Pradesh Cricket Association Stadium, ...  7 MARCH, 2024   \n",
       "1                         Harare Sports Club, Harare   6 JULY, 2024   \n",
       "2                         Harare Sports Club, Harare   7 JULY, 2024   \n",
       "3                         Harare Sports Club, Harare  10 JULY, 2024   \n",
       "4                         Harare Sports Club, Harare  13 JULY, 2024   \n",
       "5                         Harare Sports Club, Harare  14 JULY, 2024   \n",
       "\n",
       "          Time  \n",
       "0  9:30 AM IST  \n",
       "1  8:00 PM IST  \n",
       "2  8:00 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "dr.get('https://www.bcci.tv/')\n",
    "dr.maximize_window()\n",
    "fixtr=dr.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]').click()\n",
    "time.sleep(5)\n",
    "\n",
    "srs=dr.find_elements(By.XPATH,'//div[@class=\"match-card match-card-fw match-card-up ng-scope\"]/div/div[1]/div[1]/h5')\n",
    "for i in srs:\n",
    "    siries=i.text\n",
    "    Series.append(siries)\n",
    "    time.sleep(3)\n",
    "plc1=dr.find_elements(By.XPATH,'//div[@class=\"match-card match-card-fw match-card-up ng-scope\"]/div[2]/div/span[1]')\n",
    "plc2=dr.find_elements(By.XPATH,'//div[@class=\"match-card match-card-fw match-card-up ng-scope\"]/div[2]/div/span[2]')\n",
    "for i,j in zip(plc1,plc2):\n",
    "    plce1=i.text\n",
    "    plce2=j.text\n",
    "    Place.append(f'{plce1} {plce2}')\n",
    "    time.sleep(3)\n",
    "date=dr.find_elements(By.XPATH,'//div[@class=\"match-card match-card-fw match-card-up ng-scope\"]/div/div/div/div[2]/div[1]')\n",
    "for i in date:\n",
    "    dat = i.text\n",
    "    Date.append(dat)\n",
    "    time.sleep(3)\n",
    "tme=dr.find_elements(By.XPATH,'//div[@class=\"match-card match-card-fw match-card-up ng-scope\"]/div/div/div/div[2]/div[2]')\n",
    "for i in tme:\n",
    "    tm=i.text\n",
    "    Time.append(tm)\n",
    "India=pd.DataFrame({})\n",
    "India['Series']=Series\n",
    "India['Place']=Place\n",
    "India['Date']=Date\n",
    "India['Time']=Time\n",
    "India"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c67343f",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/ \n",
    "You have to find following details: A) Rank \n",
    "B) State \n",
    "C) GSDP(18-19)- at current prices \n",
    "D) GSDP(19-20)- at current prices \n",
    "E) Share(18-19) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a3c0010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(22-23)- at current prices</th>\n",
       "      <th>GSDP(21-22)- at current prices</th>\n",
       "      <th>Share(21-22)</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>8.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>8.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,241,368</td>\n",
       "      <td>2,241,368</td>\n",
       "      <td>1,962,725</td>\n",
       "      <td>8.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>8.25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,554,992</td>\n",
       "      <td>1,554,992</td>\n",
       "      <td>1,363,926</td>\n",
       "      <td>5.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,413,620</td>\n",
       "      <td>1,413,620</td>\n",
       "      <td>1,218,193</td>\n",
       "      <td>5.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,322,821</td>\n",
       "      <td>1,322,821</td>\n",
       "      <td>1,136,137</td>\n",
       "      <td>4.84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,317,728</td>\n",
       "      <td>1,317,728</td>\n",
       "      <td>1,133,837</td>\n",
       "      <td>4.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,313,391</td>\n",
       "      <td>1,313,391</td>\n",
       "      <td>1,128,907</td>\n",
       "      <td>4.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>932,470</td>\n",
       "      <td>3.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,043,759</td>\n",
       "      <td>1,043,759</td>\n",
       "      <td>904,642</td>\n",
       "      <td>3.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>994,154</td>\n",
       "      <td>994,154</td>\n",
       "      <td>870,665</td>\n",
       "      <td>3.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>774,869</td>\n",
       "      <td>774,869</td>\n",
       "      <td>670,881</td>\n",
       "      <td>2.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>751,396</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>2.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>673,107</td>\n",
       "      <td>673,107</td>\n",
       "      <td>614,227</td>\n",
       "      <td>2.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>493,167</td>\n",
       "      <td>493,167</td>\n",
       "      <td>412,612</td>\n",
       "      <td>1.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>457,608</td>\n",
       "      <td>457,608</td>\n",
       "      <td>406,416</td>\n",
       "      <td>1.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>393,722</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>1.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>302,621</td>\n",
       "      <td>302,621</td>\n",
       "      <td>272,159</td>\n",
       "      <td>1.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>227,927</td>\n",
       "      <td>227,927</td>\n",
       "      <td>199,917</td>\n",
       "      <td>0.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>195,405</td>\n",
       "      <td>195,405</td>\n",
       "      <td>176,269</td>\n",
       "      <td>0.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>82,604</td>\n",
       "      <td>0.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>72,636</td>\n",
       "      <td>72,636</td>\n",
       "      <td>62,550</td>\n",
       "      <td>0.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>45,635</td>\n",
       "      <td>0.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>44,238</td>\n",
       "      <td>0.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>42,697</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>0.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>42,756</td>\n",
       "      <td>42,756</td>\n",
       "      <td>37,557</td>\n",
       "      <td>0.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>0.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>35,124</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>31,913</td>\n",
       "      <td>0.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>27,824</td>\n",
       "      <td>0.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>0.04%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(22-23)- at current prices  \\\n",
       "0     1                Maharashtra                              -   \n",
       "1     2                 Tamil Nadu                      2,364,514   \n",
       "2     3              Uttar Pradesh                      2,257,575   \n",
       "3     4                  Karnataka                      2,241,368   \n",
       "4     5                    Gujarat                              -   \n",
       "5     6                West Bengal                      1,554,992   \n",
       "6     7                  Rajasthan                      1,413,620   \n",
       "7     8             Madhya Pradesh                      1,322,821   \n",
       "8     9             Andhra Pradesh                      1,317,728   \n",
       "9    10                  Telangana                      1,313,391   \n",
       "10   11                     Kerala                              -   \n",
       "11   12                      Delhi                      1,043,759   \n",
       "12   13                    Haryana                        994,154   \n",
       "13   14                     Odisha                        774,869   \n",
       "14   15                      Bihar                        751,396   \n",
       "15   16                     Punjab                        673,107   \n",
       "16   17                      Assam                        493,167   \n",
       "17   18               Chhattisgarh                        457,608   \n",
       "18   19                  Jharkhand                        393,722   \n",
       "19   20                Uttarakhand                        302,621   \n",
       "20   21         Jammu & Kashmir-UT                        227,927   \n",
       "21   22           Himachal Pradesh                        195,405   \n",
       "22   23                        Goa                              -   \n",
       "23   24                    Tripura                         72,636   \n",
       "24   25                 Chandigarh                              -   \n",
       "25   26                 Puducherry                              -   \n",
       "26   27                  Meghalaya                         42,697   \n",
       "27   28                     Sikkim                         42,756   \n",
       "28   29                    Manipur                              -   \n",
       "29   30          Arunachal Pradesh                              -   \n",
       "30   31                   Nagaland                              -   \n",
       "31   32                    Mizoram                              -   \n",
       "32   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(21-22)- at current prices Share(21-22)     GDP  \n",
       "0                               -    3,108,022  13.24%  \n",
       "1                       2,364,514    2,071,286   8.82%  \n",
       "2                       2,257,575    1,974,532   8.41%  \n",
       "3                       2,241,368    1,962,725   8.36%  \n",
       "4                               -    1,937,066   8.25%  \n",
       "5                       1,554,992    1,363,926   5.81%  \n",
       "6                       1,413,620    1,218,193   5.19%  \n",
       "7                       1,322,821    1,136,137   4.84%  \n",
       "8                       1,317,728    1,133,837   4.83%  \n",
       "9                       1,313,391    1,128,907   4.81%  \n",
       "10                              -      932,470   3.97%  \n",
       "11                      1,043,759      904,642   3.85%  \n",
       "12                        994,154      870,665   3.71%  \n",
       "13                        774,869      670,881   2.86%  \n",
       "14                        751,396      650,302   2.77%  \n",
       "15                        673,107      614,227   2.62%  \n",
       "16                        493,167      412,612   1.76%  \n",
       "17                        457,608      406,416   1.73%  \n",
       "18                        393,722      358,863   1.53%  \n",
       "19                        302,621      272,159   1.16%  \n",
       "20                        227,927      199,917   0.85%  \n",
       "21                        195,405      176,269   0.75%  \n",
       "22                              -       82,604   0.35%  \n",
       "23                         72,636       62,550   0.27%  \n",
       "24                              -       45,635   0.19%  \n",
       "25                              -       44,238   0.19%  \n",
       "26                         42,697       38,785   0.17%  \n",
       "27                         42,756       37,557   0.16%  \n",
       "28                              -       36,594   0.16%  \n",
       "29                              -       35,124   0.15%  \n",
       "30                              -       31,913   0.14%  \n",
       "31                              -       27,824   0.12%  \n",
       "32                              -       10,371   0.04%  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get('http://statisticstimes.com/')\n",
    "india_gdp=dr.find_element(By.XPATH,'//div[@class=\"dropdown\"][2]/div/a[3]').get_attribute('href')\n",
    "dr.get(india_gdp)\n",
    "time.sleep(5)\n",
    "st_gdp=dr.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').get_attribute('href')\n",
    "dr.get(st_gdp)\n",
    "time.sleep(5)\n",
    "Rank=[]\n",
    "State=[]\n",
    "gsdp_22_23=[]\n",
    "gsdp_21_22=[]\n",
    "share1819=[]\n",
    "GDP=[]\n",
    "rank=dr.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody/tr/td[1]')\n",
    "for i in rank[0:33]:\n",
    "    rnk=i.text\n",
    "    Rank.append(rnk)\n",
    "    time.sleep(3)\n",
    "state=dr.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody/tr/td[2]')\n",
    "for i in state[0:33]:\n",
    "    stat=i.text\n",
    "    State.append(stat)\n",
    "    time.sleep(3)\n",
    "gdp2223=dr.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody/tr/td[3]')\n",
    "for i in gdp2223[0:33]:\n",
    "    gdp23=i.text\n",
    "    gsdp_22_23.append(gdp23)\n",
    "    time.sleep(3)\n",
    "gdp2122=dr.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody/tr/td[3]')\n",
    "for i in gdp2122[0:33]:\n",
    "    gdp22=i.text\n",
    "    gsdp_21_22.append(gdp22)\n",
    "    time.sleep(3)\n",
    "share=dr.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody/tr/td[4]')\n",
    "for i in share[0:33]:\n",
    "    shr=i.text\n",
    "    share1819.append(shr)\n",
    "    time.sleep(3)\n",
    "gdp=dr.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"]/table/tbody/tr/td[5]')\n",
    "for i in gdp[0:33]:\n",
    "    g_d_p=i.text\n",
    "    GDP.append(g_d_p)\n",
    "    time.sleep(3)\n",
    "State_Economy=pd.DataFrame({})\n",
    "State_Economy['Rank']=Rank\n",
    "State_Economy['State']=State\n",
    "State_Economy['GSDP(22-23)- at current prices']=gsdp_22_23\n",
    "State_Economy['GSDP(21-22)- at current prices']=gsdp_21_22\n",
    "State_Economy['Share(21-22)']=share1819\n",
    "State_Economy['GDP']=GDP\n",
    "State_Economy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802df10",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/ \n",
    "You have to find the following details: \n",
    "A) Repository title \n",
    "B) Repository description \n",
    "C) Contributors count \n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e44bb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contribution Count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WongKinYiu / yolov9</td>\n",
       "      <td>Implementation of paper - YOLOv9: Learning Wha...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python,Shell,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mttaggart / I-S00N</td>\n",
       "      <td>Anxun Shanghai (I-SOON) Data Dump Translations...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google / gemma_pytorch</td>\n",
       "      <td>The official PyTorch implementation of Google'...</td>\n",
       "      <td>4</td>\n",
       "      <td>Python,Dockerfile,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jackfrued / Python-100-Days</td>\n",
       "      <td>Python - 100Â§©‰ªéÊñ∞ÊâãÂà∞Â§ßÂ∏à</td>\n",
       "      <td>12</td>\n",
       "      <td>Python,HTML,Jupyter Notebook.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levihsu / OOTDiffusion</td>\n",
       "      <td>Official implementation of OOTDiffusion: Outfi...</td>\n",
       "      <td>3</td>\n",
       "      <td>Python,Cuda,C++,Shell,Dockerfile,C,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google-deepmind / gemma</td>\n",
       "      <td>Open weights LLM from Google DeepMind.</td>\n",
       "      <td>-</td>\n",
       "      <td>Jupyter Notebook,Python,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google / gemma.cpp</td>\n",
       "      <td>lightweight, standalone C++ inference engine f...</td>\n",
       "      <td>5</td>\n",
       "      <td>C++,CMake,Starlark,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hiddify / hiddify-next</td>\n",
       "      <td>Multi-platform auto-proxy client, supporting S...</td>\n",
       "      <td>32</td>\n",
       "      <td>Dart,Kotlin,Swift,C++,CMake,Makefile.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SoraWebui / SoraWebui</td>\n",
       "      <td>SoraWebui is an open-source Sora web client, e...</td>\n",
       "      <td>4</td>\n",
       "      <td>TypeScript.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NoteProtocol / NoteWallet</td>\n",
       "      <td>A Command Line Wallet to Send/Receive BTC and ...</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript,JavaScript,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vvbbnn00 / WARP-Clash-API</td>\n",
       "      <td>ËØ•È°πÁõÆÂèØ‰ª•ËÆ©‰Ω†ÈÄöËøáËÆ¢ÈòÖÁöÑÊñπÂºè‰ΩøÁî®Cloudflare WARP+ÔºåËá™Âä®Ëé∑ÂèñÊµÅÈáè„ÄÇThis p...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python,HTML,Shell,Dockerfile,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lobehub / lobe-chat</td>\n",
       "      <td>ü§Ø Lobe Chat - an open-source, modern-design Ch...</td>\n",
       "      <td>63</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>danswer-ai / danswer</td>\n",
       "      <td>Ask Questions in natural language and get Answ...</td>\n",
       "      <td>50</td>\n",
       "      <td>Python,TypeScript,JavaScript,Shell,Dockerfile,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gunnarmorling / 1brc</td>\n",
       "      <td>1Ô∏è‚É£üêùüèéÔ∏è The One Billion Row Challenge -- A fun ...</td>\n",
       "      <td>178</td>\n",
       "      <td>Java,Shell.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pytorch / pytorch</td>\n",
       "      <td>Tensors and Dynamic neural networks in Python ...</td>\n",
       "      <td>3,155</td>\n",
       "      <td>Python,C++,Cuda,C,Objective-C++,CMake.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lencx / Noi</td>\n",
       "      <td>üöÄ Power Your World with AI - Explore, Extend, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>JavaScript,TypeScript,CSS,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apache / echarts</td>\n",
       "      <td>Apache ECharts is a powerful, interactive char...</td>\n",
       "      <td>218</td>\n",
       "      <td>TypeScript,JavaScript.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MegaManSec / SSH-Snake</td>\n",
       "      <td>SSH-Snake is a self-propagating, self-replicat...</td>\n",
       "      <td>-</td>\n",
       "      <td>Shell,Python,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>systemdesign42 / system-design</td>\n",
       "      <td>Building the best system design resource in th...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>qarmin / czkawka</td>\n",
       "      <td>Multi functional app to find duplicates, empty...</td>\n",
       "      <td>60</td>\n",
       "      <td>Rust,Fluent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lowRISC / opentitan</td>\n",
       "      <td>OpenTitan: Open source silicon root of trust</td>\n",
       "      <td>156</td>\n",
       "      <td>SystemVerilog,C,Python,Rust,C++,Smarty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>facebook / react-native</td>\n",
       "      <td>A framework for building native applications u...</td>\n",
       "      <td>2,612</td>\n",
       "      <td>C++,Java,JavaScript,Objective-C++,Objective-C,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ashishps1 / awesome-system-design-resources</td>\n",
       "      <td>This repository contains System Design resourc...</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chatchat-space / Langchain-Chatchat</td>\n",
       "      <td>Langchain-ChatchatÔºàÂéüLangchain-ChatGLMÔºâÂü∫‰∫é Langc...</td>\n",
       "      <td>118</td>\n",
       "      <td>Python,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>zksync / credo</td>\n",
       "      <td>-</td>\n",
       "      <td>26</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0                           WongKinYiu / yolov9   \n",
       "1                            mttaggart / I-S00N   \n",
       "2                        google / gemma_pytorch   \n",
       "3                   jackfrued / Python-100-Days   \n",
       "4                        levihsu / OOTDiffusion   \n",
       "5                       google-deepmind / gemma   \n",
       "6                            google / gemma.cpp   \n",
       "7                        hiddify / hiddify-next   \n",
       "8                         SoraWebui / SoraWebui   \n",
       "9                     NoteProtocol / NoteWallet   \n",
       "10                    vvbbnn00 / WARP-Clash-API   \n",
       "11                          lobehub / lobe-chat   \n",
       "12                         danswer-ai / danswer   \n",
       "13                         gunnarmorling / 1brc   \n",
       "14                            pytorch / pytorch   \n",
       "15                                  lencx / Noi   \n",
       "16                             apache / echarts   \n",
       "17                       MegaManSec / SSH-Snake   \n",
       "18               systemdesign42 / system-design   \n",
       "19                             qarmin / czkawka   \n",
       "20                          lowRISC / opentitan   \n",
       "21                      facebook / react-native   \n",
       "22  ashishps1 / awesome-system-design-resources   \n",
       "23          chatchat-space / Langchain-Chatchat   \n",
       "24                               zksync / credo   \n",
       "\n",
       "                                          Description Contribution Count  \\\n",
       "0   Implementation of paper - YOLOv9: Learning Wha...                  -   \n",
       "1   Anxun Shanghai (I-SOON) Data Dump Translations...                  -   \n",
       "2   The official PyTorch implementation of Google'...                  4   \n",
       "3                                 Python - 100Â§©‰ªéÊñ∞ÊâãÂà∞Â§ßÂ∏à                 12   \n",
       "4   Official implementation of OOTDiffusion: Outfi...                  3   \n",
       "5              Open weights LLM from Google DeepMind.                  -   \n",
       "6   lightweight, standalone C++ inference engine f...                  5   \n",
       "7   Multi-platform auto-proxy client, supporting S...                 32   \n",
       "8   SoraWebui is an open-source Sora web client, e...                  4   \n",
       "9   A Command Line Wallet to Send/Receive BTC and ...                  -   \n",
       "10  ËØ•È°πÁõÆÂèØ‰ª•ËÆ©‰Ω†ÈÄöËøáËÆ¢ÈòÖÁöÑÊñπÂºè‰ΩøÁî®Cloudflare WARP+ÔºåËá™Âä®Ëé∑ÂèñÊµÅÈáè„ÄÇThis p...                  -   \n",
       "11  ü§Ø Lobe Chat - an open-source, modern-design Ch...                 63   \n",
       "12  Ask Questions in natural language and get Answ...                 50   \n",
       "13  1Ô∏è‚É£üêùüèéÔ∏è The One Billion Row Challenge -- A fun ...                178   \n",
       "14  Tensors and Dynamic neural networks in Python ...              3,155   \n",
       "15  üöÄ Power Your World with AI - Explore, Extend, ...                  2   \n",
       "16  Apache ECharts is a powerful, interactive char...                218   \n",
       "17  SSH-Snake is a self-propagating, self-replicat...                  -   \n",
       "18  Building the best system design resource in th...                  -   \n",
       "19  Multi functional app to find duplicates, empty...                 60   \n",
       "20       OpenTitan: Open source silicon root of trust                156   \n",
       "21  A framework for building native applications u...              2,612   \n",
       "22  This repository contains System Design resourc...                  2   \n",
       "23  Langchain-ChatchatÔºàÂéüLangchain-ChatGLMÔºâÂü∫‰∫é Langc...                118   \n",
       "24                                                  -                 26   \n",
       "\n",
       "                                             Language  \n",
       "0                                       Python,Shell,  \n",
       "1                                                   -  \n",
       "2                                  Python,Dockerfile,  \n",
       "3                       Python,HTML,Jupyter Notebook.  \n",
       "4                 Python,Cuda,C++,Shell,Dockerfile,C,  \n",
       "5                            Jupyter Notebook,Python,  \n",
       "6                                 C++,CMake,Starlark,  \n",
       "7               Dart,Kotlin,Swift,C++,CMake,Makefile.  \n",
       "8                                         TypeScript.  \n",
       "9                              TypeScript,JavaScript,  \n",
       "10                      Python,HTML,Shell,Dockerfile,  \n",
       "11                                                     \n",
       "12  Python,TypeScript,JavaScript,Shell,Dockerfile,...  \n",
       "13                                        Java,Shell.  \n",
       "14             Python,C++,Cuda,C,Objective-C++,CMake.  \n",
       "15                         JavaScript,TypeScript,CSS,  \n",
       "16                             TypeScript,JavaScript.  \n",
       "17                                      Shell,Python,  \n",
       "18                                                  -  \n",
       "19                                       Rust,Fluent.  \n",
       "20            SystemVerilog,C,Python,Rust,C++,Smarty.  \n",
       "21  C++,Java,JavaScript,Objective-C++,Objective-C,...  \n",
       "22                                                  -  \n",
       "23                                            Python,  \n",
       "24                                                  -  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get('https://github.com/')\n",
    "time.sleep(5)\n",
    "trnd_rep=dr.find_element(By.XPATH,'//ul[@class=\"d-lg-flex list-style-none\"]/li[3]/div/div[3]/ul/li[2]/a').get_attribute('href')\n",
    "dr.get(trnd_rep)\n",
    "time.sleep(3)\n",
    "Urls=[]\n",
    "Title=[]\n",
    "Disc=[]\n",
    "contrbt=[]\n",
    "lngng=[]\n",
    "urls=dr.find_elements(By.XPATH,'//div[@class=\"Box\"]/div[2]/article/h2/a')\n",
    "for i in urls:\n",
    "    url=i.get_attribute('href')\n",
    "    Urls.append(url)\n",
    "    time.sleep(3)\n",
    "title=dr.find_elements(By.XPATH,'//div[@class=\"Box\"]/div[2]/article/h2/a')\n",
    "for i in title:\n",
    "    titl=i.text\n",
    "    Title.append(titl)\n",
    "    time.sleep(3)\n",
    "for i in Urls:\n",
    "    dr.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        descr=dr.find_element(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "        d=descr.text\n",
    "        Disc.append(d)\n",
    "        time.sleep(3)\n",
    "    except NoSuchElementException:\n",
    "        Disc.append('-')\n",
    "    try:\n",
    "        cont=dr.find_element(By.XPATH,'//div[@class=\"Layout-sidebar\"]/div/div[5]/div/h2/a/span')\n",
    "    \n",
    "        c=cont.text\n",
    "        contrbt.append(c)\n",
    "        time.sleep(3)\n",
    "    except NoSuchElementException:\n",
    "        contrbt.append('-')\n",
    "    try:\n",
    "        lngag=dr.find_element(By.XPATH,'//ul[@class=\"list-style-none\"]')\n",
    "    \n",
    "        lngage=lngag.text\n",
    "        l=l=re.sub(r'\\n(\\d+)\\.(\\d+)%\\n|\\n(\\d+)\\.(\\d+)%',\",\",lngage)\n",
    "        ln=re.sub(r',Other,','.',l)\n",
    "        lngng.append(ln)\n",
    "        time.sleep(3)\n",
    "    except NoSuchElementException:\n",
    "        lngng.append('-')\n",
    "Github=pd.DataFrame({})\n",
    "Github['Title']=Title\n",
    "Github['Description']=Disc\n",
    "Github['Contribution Count']=contrbt\n",
    "Github['Language']=lngng\n",
    "Github\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd961cee",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the \n",
    "following details: \n",
    "A) Song name \n",
    "B) Artist name \n",
    "C) Last week rank \n",
    "D) Peak rank \n",
    "E) Weeks on board \n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6898337a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas Hold 'Em</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carnival</td>\n",
       "      <td>¬•$: Kanye West &amp; Ty Dolla $ign Featuring Rich ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mmhmm</td>\n",
       "      <td>BigXthaPlug</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Prove It</td>\n",
       "      <td>21 Savage &amp; Summer Walker</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Perro Negro</td>\n",
       "      <td>Bad Bunny &amp; Feid</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sunday Service</td>\n",
       "      <td>Latto</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Song Name                                        Artist Name  \\\n",
       "0        Lovin On Me                                        Jack Harlow   \n",
       "1     Texas Hold 'Em                                            Beyonce   \n",
       "2           Carnival  ¬•$: Kanye West & Ty Dolla $ign Featuring Rich ...   \n",
       "3   Beautiful Things                                       Benson Boone   \n",
       "4       Lose Control                                        Teddy Swims   \n",
       "..               ...                                                ...   \n",
       "95             Mmhmm                                        BigXthaPlug   \n",
       "96            Monaco                                          Bad Bunny   \n",
       "97          Prove It                          21 Savage & Summer Walker   \n",
       "98       Perro Negro                                   Bad Bunny & Feid   \n",
       "99    Sunday Service                                              Latto   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks On Board  \n",
       "0               1         1             14  \n",
       "1               -         -              1  \n",
       "2               -         -              1  \n",
       "3               3         3              4  \n",
       "4               2         2             27  \n",
       "..            ...       ...            ...  \n",
       "95             83        83              8  \n",
       "96             77        77             18  \n",
       "97             75        75              5  \n",
       "98             82        82             15  \n",
       "99              -         -              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get('https://www.billboard.com/')\n",
    "chart_btn_path='//div[@class=\"js-Header-contents\"]/div/div/div/div[2]/div/nav/ul/li[1]/a'\n",
    "top100_path_href='//div[@class=\"u-flex-grow-0 lrv-u-text-align-center\"]/span/a'\n",
    "sname_path='//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/h3'\n",
    "aname_path='//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/span'\n",
    "last_w_rank_path='//li[@class=\"lrv-u-width-100p\"]/ul/li[4]/span'\n",
    "peak_rank_path='//li[@class=\"lrv-u-width-100p\"]/ul/li[4]/span'\n",
    "week_board_path='//li[@class=\"lrv-u-width-100p\"]/ul/li[6]/span'\n",
    "chart_btn=dr.find_element(By.XPATH,chart_btn_path).get_attribute('href')\n",
    "dr.get(chart_btn)\n",
    "time.sleep(3)\n",
    "top100_btn=dr.find_element(By.XPATH,top100_path_href).get_attribute('href')\n",
    "dr.get(top100_btn)\n",
    "time.sleep(3)\n",
    "sname=[]\n",
    "aname=[]\n",
    "last_w_rank=[]\n",
    "peak_rank=[]\n",
    "week_board=[]\n",
    "names=dr.find_elements(By.XPATH,sname_path)\n",
    "for i in names:\n",
    "    nm=i.text\n",
    "    sname.append(nm)\n",
    "    time.sleep(3)\n",
    "namea=dr.find_elements(By.XPATH,aname_path)\n",
    "for i in namea:\n",
    "    nma=i.text\n",
    "    aname.append(nma)\n",
    "    time.sleep(3)\n",
    "lastw=dr.find_elements(By.XPATH,last_w_rank_path)\n",
    "for i in lastw:\n",
    "    lstw=i.text\n",
    "    last_w_rank.append(lstw)\n",
    "    time.sleep(3)\n",
    "pkrank=dr.find_elements(By.XPATH,peak_rank_path)\n",
    "for i in pkrank:\n",
    "    pk=i.text\n",
    "    peak_rank.append(pk)\n",
    "    time.sleep(3)\n",
    "wkbrd=dr.find_elements(By.XPATH,week_board_path)\n",
    "for i in wkbrd:\n",
    "    wk=i.text\n",
    "    week_board.append(wk)\n",
    "    time.sleep(3)\n",
    "HOT100=pd.DataFrame({})\n",
    "HOT100['Song Name']=sname\n",
    "HOT100['Artist Name']=aname\n",
    "HOT100['Last Week Rank']=last_w_rank\n",
    "HOT100['Peak Rank']=peak_rank\n",
    "HOT100['Weeks On Board']=week_board\n",
    "HOT100\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757475bf",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "6. Scrape the details of Highest selling novels. \n",
    "A) Book name \n",
    "B) Author name \n",
    "C) Volumes sold \n",
    "D) Publisher \n",
    "E) Genre \n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee859eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Auther Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Auther Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dr=webdriver.Chrome()\n",
    "dr.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "time.sleep(5)\n",
    "bname=[]\n",
    "aname=[]\n",
    "v_sold=[]\n",
    "publisher=[]\n",
    "genre=[]\n",
    "bname_path='//div[@class=\"embed block\"]/table/tbody/tr/td[2]'\n",
    "aname_path='//div[@class=\"embed block\"]/table/tbody/tr/td[3]'\n",
    "v_sold_path='//div[@class=\"embed block\"]/table/tbody/tr/td[4]'\n",
    "publ_path='//div[@class=\"embed block\"]/table/tbody/tr/td[5]'\n",
    "genre_path='//div[@class=\"embed block\"]/table/tbody/tr/td[6]'\n",
    "title=dr.find_elements(By.XPATH,bname_path)\n",
    "for i in title:\n",
    "    ttl=i.text\n",
    "    bname.append(ttl)\n",
    "    time.sleep(3)\n",
    "a_name=dr.find_elements(By.XPATH,aname_path)\n",
    "for i in a_name:\n",
    "    anm=i.text\n",
    "    aname.append(anm)\n",
    "    time.sleep(3)\n",
    "vsold=dr.find_elements(By.XPATH,v_sold_path)\n",
    "for i in vsold:\n",
    "    vsld=i.text\n",
    "    v_sold.append(vsld)\n",
    "    time.sleep(3)\n",
    "pblshr=dr.find_elements(By.XPATH,publ_path)\n",
    "for i in pblshr:\n",
    "    pbl=i.text\n",
    "    publisher.append(pbl)\n",
    "    time.sleep(3)\n",
    "gnre=dr.find_elements(By.XPATH,genre_path)\n",
    "for i in gnre:\n",
    "    gnr=i.text\n",
    "    genre.append(gnr)\n",
    "    time.sleep(3)\n",
    "Books=pd.DataFrame({})\n",
    "Books['Book Name']=bname\n",
    "Books['Auther Name']=aname\n",
    "Books['Volume Sold']=v_sold\n",
    "Books['Publisher']=publisher    \n",
    "Books['Genre']=genre\n",
    "Books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d178497b",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "to find the following details: \n",
    "A) Name \n",
    "B) Year span \n",
    "C) Genre \n",
    "D) Run time \n",
    "E) Ratings \n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56f89e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: element click intercepted: Element is not clickable at point (400, 10261)\n",
      "  (Session info: chrome=122.0.6261.58)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7B6CC4C82+3505170]\n",
      "\t(No symbol) [0x00007FF7B68F0852]\n",
      "\t(No symbol) [0x00007FF7B67A4145]\n",
      "\t(No symbol) [0x00007FF7B67F0C70]\n",
      "\t(No symbol) [0x00007FF7B67EEA9B]\n",
      "\t(No symbol) [0x00007FF7B67EC2A4]\n",
      "\t(No symbol) [0x00007FF7B67EB035]\n",
      "\t(No symbol) [0x00007FF7B67DF978]\n",
      "\t(No symbol) [0x00007FF7B680BE8A]\n",
      "\t(No symbol) [0x00007FF7B67DF27A]\n",
      "\t(No symbol) [0x00007FF7B680C0A0]\n",
      "\t(No symbol) [0x00007FF7B68283B2]\n",
      "\t(No symbol) [0x00007FF7B680BC33]\n",
      "\t(No symbol) [0x00007FF7B67DD618]\n",
      "\t(No symbol) [0x00007FF7B67DE6B1]\n",
      "\tGetHandleVerifier [0x00007FF7B6CF67DD+3708781]\n",
      "\tGetHandleVerifier [0x00007FF7B6D4FC5D+4074477]\n",
      "\tGetHandleVerifier [0x00007FF7B6D47DDF+4042095]\n",
      "\tGetHandleVerifier [0x00007FF7B6A1A136+708806]\n",
      "\t(No symbol) [0x00007FF7B68FCB0F]\n",
      "\t(No symbol) [0x00007FF7B68F7D14]\n",
      "\t(No symbol) [0x00007FF7B68F7E6C]\n",
      "\t(No symbol) [0x00007FF7B68E79A4]\n",
      "\tBaseThreadInitThunk [0x00007FFDA3467344+20]\n",
      "\tRtlUserThreadStart [0x00007FFDA52626B1+33]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dr=webdriver.Chrome()\n",
    "dr.get('https://www.imdb.com/search/title/?title_type=tv_series&sort=num_votes,desc')\n",
    "time.sleep(5)\n",
    "dr.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    \n",
    "time.sleep(10)\n",
    "try:\n",
    "    more_btn=dr.find_element(By.XPATH,'/html/body/div[2]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span')\n",
    "    more_btn.click()\n",
    "except ElementClickInterceptedException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb7e8e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Game of Thrones]</td>\n",
       "      <td>2011‚Äì2019</td>\n",
       "      <td>9.2\\n (2.3M)</td>\n",
       "      <td>(2,259,687,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ Breaking Bad]</td>\n",
       "      <td>2008‚Äì2013</td>\n",
       "      <td>9.5\\n (2.1M)</td>\n",
       "      <td>(2,107,220,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ Stranger Things]</td>\n",
       "      <td>2016‚Äì2025</td>\n",
       "      <td>8.7\\n (1.3M)</td>\n",
       "      <td>(1,318,440,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ Friends]</td>\n",
       "      <td>1994‚Äì2004</td>\n",
       "      <td>8.9\\n (1.1M)</td>\n",
       "      <td>(1,077,620,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ The Walking Dead]</td>\n",
       "      <td>2010‚Äì2022</td>\n",
       "      <td>8.1\\n (1.1M)</td>\n",
       "      <td>(1,070,614,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ Sherlock]</td>\n",
       "      <td>2010‚Äì2017</td>\n",
       "      <td>9.1\\n (989K)</td>\n",
       "      <td>(988,505,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ The Big Bang Theory]</td>\n",
       "      <td>2007‚Äì2019</td>\n",
       "      <td>8.1\\n (860K)</td>\n",
       "      <td>(860,279,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ Dexter]</td>\n",
       "      <td>2006‚Äì2013</td>\n",
       "      <td>8.7\\n (759K)</td>\n",
       "      <td>(758,975,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ How I Met Your Mother]</td>\n",
       "      <td>2005‚Äì2014</td>\n",
       "      <td>8.3\\n (723K)</td>\n",
       "      <td>(723,488,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ The Office]</td>\n",
       "      <td>2005‚Äì2013</td>\n",
       "      <td>9.0\\n (699K)</td>\n",
       "      <td>(698,806,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[ True Detective]</td>\n",
       "      <td>2014‚Äì</td>\n",
       "      <td>8.9\\n (642K)</td>\n",
       "      <td>(642,077,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[ Peaky Blinders]</td>\n",
       "      <td>2013‚Äì2022</td>\n",
       "      <td>8.8\\n (637K)</td>\n",
       "      <td>(636,521,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[ Better Call Saul]</td>\n",
       "      <td>2015‚Äì2022</td>\n",
       "      <td>9.0\\n (636K)</td>\n",
       "      <td>(635,678,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[ The Boys]</td>\n",
       "      <td>2019‚Äì</td>\n",
       "      <td>8.7\\n (634K)</td>\n",
       "      <td>(633,858,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[ Black Mirror]</td>\n",
       "      <td>2011‚Äì</td>\n",
       "      <td>8.7\\n (632K)</td>\n",
       "      <td>(632,447,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[ Rick and Morty]</td>\n",
       "      <td>2013‚Äì</td>\n",
       "      <td>9.1\\n (594K)</td>\n",
       "      <td>(593,879,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[ Lost]</td>\n",
       "      <td>2004‚Äì2010</td>\n",
       "      <td>8.3\\n (590K)</td>\n",
       "      <td>(589,795,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[ The Mandalorian]</td>\n",
       "      <td>2019‚Äì</td>\n",
       "      <td>8.7\\n (580K)</td>\n",
       "      <td>(579,786,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[ Vikings]</td>\n",
       "      <td>2013‚Äì2020</td>\n",
       "      <td>8.5\\n (575K)</td>\n",
       "      <td>(575,390,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[ Prison Break]</td>\n",
       "      <td>2005‚Äì2017</td>\n",
       "      <td>8.3\\n (574K)</td>\n",
       "      <td>(574,415,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[ The Witcher]</td>\n",
       "      <td>2019‚Äì</td>\n",
       "      <td>8.0\\n (565K)</td>\n",
       "      <td>(564,664,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[ Squid Game]</td>\n",
       "      <td>2021‚Äì</td>\n",
       "      <td>8.0\\n (531K)</td>\n",
       "      <td>(530,577,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[ Westworld]</td>\n",
       "      <td>2016‚Äì2022</td>\n",
       "      <td>8.5\\n (529K)</td>\n",
       "      <td>(529,326,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[ House of Cards]</td>\n",
       "      <td>2013‚Äì2018</td>\n",
       "      <td>8.6\\n (528K)</td>\n",
       "      <td>(527,983,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[ Money Heist]</td>\n",
       "      <td>2017‚Äì2021</td>\n",
       "      <td>8.2\\n (526K)</td>\n",
       "      <td>(526,061,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[ House]</td>\n",
       "      <td>2004‚Äì2012</td>\n",
       "      <td>8.7\\n (504K)</td>\n",
       "      <td>(504,388,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[ The Last of Us]</td>\n",
       "      <td>2023‚Äì</td>\n",
       "      <td>8.8\\n (501K)</td>\n",
       "      <td>(501,179,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[ Attack on Titan]</td>\n",
       "      <td>2013‚Äì2023</td>\n",
       "      <td>9.1\\n (498K)</td>\n",
       "      <td>(497,914,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[ Supernatural]</td>\n",
       "      <td>2005‚Äì2020</td>\n",
       "      <td>8.4\\n (479K)</td>\n",
       "      <td>(478,618,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[ Modern Family]</td>\n",
       "      <td>2009‚Äì2020</td>\n",
       "      <td>8.5\\n (477K)</td>\n",
       "      <td>(476,570,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[ Suits]</td>\n",
       "      <td>2011‚Äì2019</td>\n",
       "      <td>8.4\\n (471K)</td>\n",
       "      <td>(471,445,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[ Daredevil]</td>\n",
       "      <td>2015‚Äì2018</td>\n",
       "      <td>8.6\\n (471K)</td>\n",
       "      <td>(470,929,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[ Narcos]</td>\n",
       "      <td>2015‚Äì2017</td>\n",
       "      <td>8.8\\n (465K)</td>\n",
       "      <td>(465,230,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[ The Sopranos]</td>\n",
       "      <td>1999‚Äì2007</td>\n",
       "      <td>9.2\\n (462K)</td>\n",
       "      <td>(462,044,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[ Arrow]</td>\n",
       "      <td>2012‚Äì2020</td>\n",
       "      <td>7.5\\n (445K)</td>\n",
       "      <td>(444,607,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[ Dark]</td>\n",
       "      <td>2017‚Äì2020</td>\n",
       "      <td>8.7\\n (437K)</td>\n",
       "      <td>(437,164,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[ The Simpsons]</td>\n",
       "      <td>1989‚Äì</td>\n",
       "      <td>8.7\\n (433K)</td>\n",
       "      <td>(432,713,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[ Fargo]</td>\n",
       "      <td>2014‚Äì2024</td>\n",
       "      <td>8.9\\n (416K)</td>\n",
       "      <td>(415,729,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[ Mr,  Robot]</td>\n",
       "      <td>2015‚Äì2019</td>\n",
       "      <td>8.5\\n (415K)</td>\n",
       "      <td>(414,842,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[ Loki]</td>\n",
       "      <td>2021‚Äì2023</td>\n",
       "      <td>8.2\\n (406K)</td>\n",
       "      <td>(406,156,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[ South Park]</td>\n",
       "      <td>1997‚Äì</td>\n",
       "      <td>8.7\\n (403K)</td>\n",
       "      <td>(403,089,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[ The Wire]</td>\n",
       "      <td>2002‚Äì2008</td>\n",
       "      <td>9.3\\n (373K)</td>\n",
       "      <td>(372,671,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[ Death Note]</td>\n",
       "      <td>2006‚Äì2007</td>\n",
       "      <td>8.9\\n (372K)</td>\n",
       "      <td>(372,123,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[ The Flash]</td>\n",
       "      <td>2014‚Äì2023</td>\n",
       "      <td>7.5\\n (367K)</td>\n",
       "      <td>(366,781,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[ House of the Dragon]</td>\n",
       "      <td>2022‚Äì</td>\n",
       "      <td>8.4\\n (363K)</td>\n",
       "      <td>(363,218,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[ Family Guy]</td>\n",
       "      <td>1999‚Äì2025</td>\n",
       "      <td>8.2\\n (362K)</td>\n",
       "      <td>(361,704,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[ Homeland]</td>\n",
       "      <td>2011‚Äì2020</td>\n",
       "      <td>8.3\\n (359K)</td>\n",
       "      <td>(359,078,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[ Avatar: The Last Airbender]</td>\n",
       "      <td>2005‚Äì2008</td>\n",
       "      <td>9.3\\n (358K)</td>\n",
       "      <td>(357,697,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[ Brooklyn Nine-Nine]</td>\n",
       "      <td>2013‚Äì2021</td>\n",
       "      <td>8.4\\n (356K)</td>\n",
       "      <td>(355,731,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[ Wednesday]</td>\n",
       "      <td>2022‚Äì</td>\n",
       "      <td>8.1\\n (353K)</td>\n",
       "      <td>(352,770,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  Year Span        Rating          Vote\n",
       "0              [ Game of Thrones]  2011‚Äì2019  9.2\\n (2.3M)  (2,259,687,)\n",
       "1                 [ Breaking Bad]  2008‚Äì2013  9.5\\n (2.1M)  (2,107,220,)\n",
       "2              [ Stranger Things]  2016‚Äì2025  8.7\\n (1.3M)  (1,318,440,)\n",
       "3                      [ Friends]  1994‚Äì2004  8.9\\n (1.1M)  (1,077,620,)\n",
       "4             [ The Walking Dead]  2010‚Äì2022  8.1\\n (1.1M)  (1,070,614,)\n",
       "5                     [ Sherlock]  2010‚Äì2017  9.1\\n (989K)    (988,505,)\n",
       "6          [ The Big Bang Theory]  2007‚Äì2019  8.1\\n (860K)    (860,279,)\n",
       "7                       [ Dexter]  2006‚Äì2013  8.7\\n (759K)    (758,975,)\n",
       "8        [ How I Met Your Mother]  2005‚Äì2014  8.3\\n (723K)    (723,488,)\n",
       "9                   [ The Office]  2005‚Äì2013  9.0\\n (699K)    (698,806,)\n",
       "10              [ True Detective]      2014‚Äì  8.9\\n (642K)    (642,077,)\n",
       "11              [ Peaky Blinders]  2013‚Äì2022  8.8\\n (637K)    (636,521,)\n",
       "12            [ Better Call Saul]  2015‚Äì2022  9.0\\n (636K)    (635,678,)\n",
       "13                    [ The Boys]      2019‚Äì  8.7\\n (634K)    (633,858,)\n",
       "14                [ Black Mirror]      2011‚Äì  8.7\\n (632K)    (632,447,)\n",
       "15              [ Rick and Morty]      2013‚Äì  9.1\\n (594K)    (593,879,)\n",
       "16                        [ Lost]  2004‚Äì2010  8.3\\n (590K)    (589,795,)\n",
       "17             [ The Mandalorian]      2019‚Äì  8.7\\n (580K)    (579,786,)\n",
       "18                     [ Vikings]  2013‚Äì2020  8.5\\n (575K)    (575,390,)\n",
       "19                [ Prison Break]  2005‚Äì2017  8.3\\n (574K)    (574,415,)\n",
       "20                 [ The Witcher]      2019‚Äì  8.0\\n (565K)    (564,664,)\n",
       "21                  [ Squid Game]      2021‚Äì  8.0\\n (531K)    (530,577,)\n",
       "22                   [ Westworld]  2016‚Äì2022  8.5\\n (529K)    (529,326,)\n",
       "23              [ House of Cards]  2013‚Äì2018  8.6\\n (528K)    (527,983,)\n",
       "24                 [ Money Heist]  2017‚Äì2021  8.2\\n (526K)    (526,061,)\n",
       "25                       [ House]  2004‚Äì2012  8.7\\n (504K)    (504,388,)\n",
       "26              [ The Last of Us]      2023‚Äì  8.8\\n (501K)    (501,179,)\n",
       "27             [ Attack on Titan]  2013‚Äì2023  9.1\\n (498K)    (497,914,)\n",
       "28                [ Supernatural]  2005‚Äì2020  8.4\\n (479K)    (478,618,)\n",
       "29               [ Modern Family]  2009‚Äì2020  8.5\\n (477K)    (476,570,)\n",
       "30                       [ Suits]  2011‚Äì2019  8.4\\n (471K)    (471,445,)\n",
       "31                   [ Daredevil]  2015‚Äì2018  8.6\\n (471K)    (470,929,)\n",
       "32                      [ Narcos]  2015‚Äì2017  8.8\\n (465K)    (465,230,)\n",
       "33                [ The Sopranos]  1999‚Äì2007  9.2\\n (462K)    (462,044,)\n",
       "34                       [ Arrow]  2012‚Äì2020  7.5\\n (445K)    (444,607,)\n",
       "35                        [ Dark]  2017‚Äì2020  8.7\\n (437K)    (437,164,)\n",
       "36                [ The Simpsons]      1989‚Äì  8.7\\n (433K)    (432,713,)\n",
       "37                       [ Fargo]  2014‚Äì2024  8.9\\n (416K)    (415,729,)\n",
       "38                  [ Mr,  Robot]  2015‚Äì2019  8.5\\n (415K)    (414,842,)\n",
       "39                        [ Loki]  2021‚Äì2023  8.2\\n (406K)    (406,156,)\n",
       "40                  [ South Park]      1997‚Äì  8.7\\n (403K)    (403,089,)\n",
       "41                    [ The Wire]  2002‚Äì2008  9.3\\n (373K)    (372,671,)\n",
       "42                  [ Death Note]  2006‚Äì2007  8.9\\n (372K)    (372,123,)\n",
       "43                   [ The Flash]  2014‚Äì2023  7.5\\n (367K)    (366,781,)\n",
       "44         [ House of the Dragon]      2022‚Äì  8.4\\n (363K)    (363,218,)\n",
       "45                  [ Family Guy]  1999‚Äì2025  8.2\\n (362K)    (361,704,)\n",
       "46                    [ Homeland]  2011‚Äì2020  8.3\\n (359K)    (359,078,)\n",
       "47  [ Avatar: The Last Airbender]  2005‚Äì2008  9.3\\n (358K)    (357,697,)\n",
       "48          [ Brooklyn Nine-Nine]  2013‚Äì2021  8.4\\n (356K)    (355,731,)\n",
       "49                   [ Wednesday]      2022‚Äì  8.1\\n (353K)    (352,770,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "name_path='//div[@class=\"sc-f24f1c5c-4 eZiMbd dli-parent\"]/div/div[2]/div/a'\n",
    "span_path='//div[@class=\"sc-f24f1c5c-4 eZiMbd dli-parent\"]/div/div[2]/div[2]/span[1]'\n",
    "rating_path='//div[@class=\"sc-f24f1c5c-4 eZiMbd dli-parent\"]/div/div[2]/span/div/span'\n",
    "vote_path='//div[@class=\"sc-f24f1c5c-0 cPpOqU\"]'\n",
    "name=[]\n",
    "span=[]\n",
    "rating=[]\n",
    "vate=[]\n",
    "name_=dr.find_elements(By.XPATH,name_path)\n",
    "for i in name_:\n",
    "    nm=i.text\n",
    "    nm1=re.findall(r'([^0-9.]+)',nm).tuple\n",
    "    name.append(nm1)\n",
    "    time.sleep(3)\n",
    "spn=dr.find_elements(By.XPATH,span_path)\n",
    "for i in spn:\n",
    "    sp=i.text\n",
    "    span.append(sp)\n",
    "    time.sleep(3)\n",
    "rting=dr.find_elements(By.XPATH,rating_path)\n",
    "for i in rting:\n",
    "    rtng=i.text\n",
    "    rating.append(rtng)\n",
    "    time.sleep(3)\n",
    "vote=dr.find_elements(By.XPATH,vote_path)\n",
    "for i in vote:\n",
    "    vt=i.text\n",
    "    vt1=re.findall(r'\\d.+\\d',vt)\n",
    "    vt2=tuple(vt1)\n",
    "    vate.append(vt2)\n",
    "    time.sleep(3)\n",
    "TVSERIES=pd.DataFrame({})\n",
    "TVSERIES['Name']=name\n",
    "TVSERIES['Year Span']=span\n",
    "TVSERIES['Rating']=rating\n",
    "TVSERIES['Vote']=vate\n",
    "TVSERIES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21729763",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/ You \n",
    "have to find the following details: \n",
    "A) Dataset name \n",
    "B) Data type \n",
    "C) Task \n",
    "D) Attribute type \n",
    "E) No of instances \n",
    "F) No of attribute G) Year \n",
    " Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f59cb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No Of Instance</th>\n",
       "      <th>No Of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>16</td>\n",
       "      <td>9/13/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>7</td>\n",
       "      <td>10/5/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900</td>\n",
       "      <td>7</td>\n",
       "      <td>8/13/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>6/30/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>11</td>\n",
       "      <td>10/6/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Dataset Name                  Data Type  \\\n",
       "0                                   Iris                    Tabular   \n",
       "1                       Dry Bean Dataset               Multivariate   \n",
       "2                          Heart Disease               Multivariate   \n",
       "3             Rice (Cammeo and Osmancik)               Multivariate   \n",
       "4                                  Adult               Multivariate   \n",
       "..                                   ...                        ...   \n",
       "95                                Raisin               Multivariate   \n",
       "96  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "97                                  Wine                    Tabular   \n",
       "98                          Wine Quality               Multivariate   \n",
       "99                              Diabetes  Multivariate, Time-Series   \n",
       "\n",
       "                          Task              Attribute Type No Of Instance  \\\n",
       "0               Classification                        Real            150   \n",
       "1               Classification               Integer, Real          13611   \n",
       "2               Classification  Categorical, Integer, Real            303   \n",
       "3               Classification                        Real           3810   \n",
       "4               Classification        Categorical, Integer          48842   \n",
       "..                         ...                         ...            ...   \n",
       "95              Classification               Real, Integer            900   \n",
       "96              Classification                        Real            569   \n",
       "97              Classification               Integer, Real            178   \n",
       "98  Classification, Regression                        Real           4898   \n",
       "99              Classification        Categorical, Integer              1   \n",
       "\n",
       "   No Of Attribute        Year  \n",
       "0                4   6/30/1988  \n",
       "1               16   9/13/2020  \n",
       "2               13   6/30/1988  \n",
       "3                7   10/5/2019  \n",
       "4               14   4/30/1996  \n",
       "..             ...         ...  \n",
       "95               7   8/13/2023  \n",
       "96              30  10/31/1995  \n",
       "97              13   6/30/1991  \n",
       "98              11   10/6/2009  \n",
       "99              20           -  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get('https://archive.ics.uci.edu/')\n",
    "vw_dtast_btn=dr.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]').click()\n",
    "urls=[]\n",
    "delay=10\n",
    "ur=dr.find_elements(By.XPATH,'//div[@class=\"rounded-box bg-base-100\"]/div/div/div/a')\n",
    "for i in range(0,10):\n",
    "    time.sleep(3)\n",
    "    for j in ur:\n",
    "        url=j.get_attribute('href')\n",
    "        urls.append(url)\n",
    "    \n",
    "dataset_nm_path='//div[@class=\"relative flex flex w-full items-center gap-4 bg-primary p-2\"]/div[2]/div/h1' \n",
    "datatype_path='//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[1]/p' \n",
    "task_path='//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[3]/p' \n",
    "attributetype_path='//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[4]/p'\n",
    "noist_path='//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[5]/p'\n",
    "no_attribute_path='//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[6]/p'\n",
    "year_path='//h2[@class=\"text-sm text-primary-content\"]'\n",
    "dataset_name=[]\n",
    "datatype=[]\n",
    "task=[]\n",
    "attributetype=[]\n",
    "no_of_instance=[]\n",
    "no_of_attribute=[]\n",
    "year=[]\n",
    "for i in urls:\n",
    "    dr.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        dtst=dr.find_element(By.XPATH,dataset_nm_path).text\n",
    "        dataset_name.append(dtst)\n",
    "    except NoSuchElementException:\n",
    "        dataset_name.append('-')\n",
    "    try:\n",
    "        dttyp=dr.find_element(By.XPATH,datatype_path).text\n",
    "        datatype.append(dttyp)\n",
    "    except NoSuchElementException:\n",
    "        datatype.append('-')\n",
    "    try:\n",
    "        tsk=dr.find_element(By.XPATH,task_path).text\n",
    "        task.append(tsk)\n",
    "    except NoSuchElementException:\n",
    "        task.append('-')\n",
    "    try:\n",
    "        atrbt=dr.find_element(By.XPATH,attributetype_path).text\n",
    "        attributetype.append(atrbt)\n",
    "    except NoSuchElementException:\n",
    "        attributetype.append('-')\n",
    "    try:\n",
    "        noins=dr.find_element(By.XPATH,noist_path).text\n",
    "        no_of_instance.append(noins)\n",
    "    except NoSuchElementException:\n",
    "        no_of_instance.append('-')\n",
    "    try:\n",
    "        noatr=dr.find_element(By.XPATH,no_attribute_path).text\n",
    "        no_of_attribute.append(noatr)\n",
    "    except NoSuchElemenetException:\n",
    "        no_of_attribute.append('-')\n",
    "    try:\n",
    "        yr=dr.find_element(By.XPATH,year_path).text\n",
    "        yr1=re.findall(r'[^A-z]+',yr)[1]\n",
    "        yr2=re.sub(r'\\s','',yr1)\n",
    "        year.append(yr2)\n",
    "    except NoSuchElementException:\n",
    "        year.append('-')\n",
    "UCI=pd.DataFrame({})\n",
    "UCI['Dataset Name']=dataset_name\n",
    "UCI['Data Type']=datatype\n",
    "UCI['Task']=task\n",
    "UCI['Attribute Type']=attributetype\n",
    "UCI['No Of Instance']=no_of_instance\n",
    "UCI['No Of Attribute']=no_of_attribute\n",
    "UCI['Year']=year\n",
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cd118b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "findall() missing 1 required positional argument: 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[nbkdnbk]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m d\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([^(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m])])\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m d\n",
      "\u001b[1;31mTypeError\u001b[0m: findall() missing 1 required positional argument: 'string'"
     ]
    }
   ],
   "source": [
    "text='[nbkdnbk]'\n",
    "d=re.findall(r'([^(\\[\\])])')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef5f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
